"""Module to label images in project.db."""

import argparse
import io
from itertools import chain
from pathlib import Path
from typing import List

import pandas as pd
import requests
from joblib import load
from PIL import Image
from sklearn.pipeline import Pipeline
from sqlalchemy import create_engine
from tqdm import tqdm

from feature_extraction import FeatureExtractor


class ImageLabeler:
    """Class for labeling images in the projet.db.

    Can be used from the console to label images that are already
    in the DB, or can be used in the scraper during sourcing to label incoming
    images.
    """

    def __init__(self, model: Pipeline) -> None:
        """Initialize ImageLabeler.

        Args:
            - model (Pipeline): The model generated by the dvc pipeline.
        """
        self.model = model
        self.extractor = FeatureExtractor()

    def label_images(self, to_label: List):
        """Label a list of images.

        Args:
            to_label (List[PIL.Image]): List of images to label.
        """
        # First, let's extract the features from the given image(s)
        features = self._generate_features(to_label)

        # Next, the given features can be labeled as either 0 or 1
        # (not-worn/worn).
        labels = self._label_features(features)

        return labels

    def _generate_features(self, to_label):
        # The feature extractor can be used to convert images to a matrix
        extractor = FeatureExtractor()
        features = extractor.extract_features(images=to_label)

        return features

    def _label_features(self, features):
        # If the feature matrix is passed all at once, the model will consume
        # far to much memory during prediction. To avoid that, the features
        # will be split in chunks of 100 rows with the help of a generator. The
        # resulting predictions will then be unpacked into a single continous
        # array.
        batchsize = 100  # This will be the number of rows in each batch.

        # Split the batches with a generator expression.
        split_batches = (
            features[100 * i: 100 * (i + 1)]
            for i in range(features.shape[0] // batchsize + 1)
            )
        # Get a list of arrays of labels
        labels = [
            self.model.predict(batch) for batch in split_batches
            ]

        # Unpack the list of arrays of labels into a list of labels
        labels = list(chain.from_iterable(labels))

        return labels


def label_in_db(model_path: str, db_path: str, brand: str):
    """Get labels for URLs saved in a DB.

    Args:
        - model_path (str): Where to load the model from.
        - db_path (str): Where to load the image URLs from.
        - brand (str): Only label images for this brand. Mandatory to avoid
            loading a too huge amount of data.
    """
    # First load the model
    model = load(model_path)

    # Then get the image URLs from the passed DB path
    db_posix = Path(__file__).absolute().parent.parent.joinpath(db_path)
    if not db_posix.is_file():
        raise FileNotFoundError(f"No DB at {db_posix.as_posix()}")
    e = create_engine(f"sqlite:///{db_posix.as_posix()}")
    image_urls = _load_images(e, brand)

    # Now label images...
    labeler = ImageLabeler(model=model)
    images = [
        Image.open(io.BytesIO(requests.get(url).content))
        for url
        in tqdm(image_urls, total=len(image_urls), desc="Loading images...")
        ]
    labels = labeler.label_images(images)

    # ... and package them in a dictionary, for the later upload
    upload = dict(zip(image_urls, labels))

    # And label directly in the DB
    upload_iterator = tqdm(
        upload.items(), total=len(upload), desc="Uplaoding Labels"
        )
    with e.connect() as con:
        for url, label in upload_iterator:
            con.execute(
                f"UPDATE images SET flag_model={label} WHERE image='{url}'"
                )


def _load_images(engine, brand):
    # Load from DB, while filtering by brand and where it is unlabeled
    image_urls = pd.read_sql(
        "SELECT image "
        "FROM images AS im "
        "JOIN pieces AS pi "
        "ON pi.item_id=im.item_id "
        f"WHERE brand = '{brand}' AND (flag_model IS NULL OR flag_model = -1)",
        engine
    ).image.tolist()

    return tuple(set(image_urls))  # URLs should be unique (for efficiency),
    # but need to have a fixed position


if __name__ == "__main__":
    parser = argparse.ArgumentParser("console_call")
    parser.add_argument(
        "--model_path", dest="model_path", help="Model to use.", type=str
        )
    parser.add_argument(
        "--db_path", dest="db_path", help="DB to use.", type=str
        )
    parser.add_argument(
        "--brand", dest="brand", help="Brand to filter by.", type=str
        )

    args = parser.parse_args()

    label_in_db(
        model_path=args.model_path, db_path=args.db_path, brand=args.brand
        )
